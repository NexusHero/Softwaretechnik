\section{Trainingsvorgang}

Der Trainingsvorgang basiert auf ein mehrschichtiges Deep Learning-Netzwerk. Dieses Netzwerk aus Neuronen besteht aus drei Schichten:
\begin{description}
	\item Input-Schicht
	\item Hidden-Schicht 
	\item Output-Schicht
\end{description}
Die Input-Schicht stellt dabei die Eingangsdaten dar, welche als Trainingsmaterial dienen. Bei diesen Daten handelt es sich um Sprachaufnahmen. Bei Bedarf lassen sich diese Aufnahmen dementsprechend vorverarbeitet werden, wie zum Beispiel durch Einsatz von Filtern. Anschlie√üend k√∂nnen die beschrifteten Daten in die Netztopologie eingespeist werden. Eine Vorklassifizierung der Sprache f√ºhrt zu erhˆhten der Spracherkennungsrate von mehreren Sprachen. In den Hidden-Layer geschieht das Training. Dabei wird die Sigmoid-Funktion als Aktivit√§tsfunktion eingesetzt. Diese Funktion beschreibt den Korrelation zwischen Input-Wert und  Aktivit√§tslevel eines Neurons dar. Dabei wird der Netzinput auf die X-Achse eingetragen. Auf die Y-Achse wird der zugeh√∂rige Aktivit√§tslevel eingetragen. Der Aktivit√§tslevel wird durch eine  Ausgabefunktion dann in den Output transformiert, den das Neuron an andere Neuronen weitersendet\cite{Neuronal31:online}. Das Netz wird beginnend von der Input-Schicht bis Output-Schicht vollst√§ndig durchlaufen. 
\begin{equation}
sigm(x)=\frac{ 1 }{1+e^{-x}  }
\label{normal}
\end{equation}
Sobald die Output-Schicht erreicht ist, wird das Netz r√ºckw√§rts durchlaufen. Dieses Verfahren wird auch Gradientenabstiegsverfahren genannt und wird ben√∂tigt, um fehlerhafte Kantengewichte herauszufinden und anzupassen. Die Kantengewichte des Netzes werden anfangs mit null initialisiert, sodass die Kantengewichtungen korrigiert werden m√ºssen. Die Ableitung der Sigmoid-Funktion kommt bei der Korrekturberechnung zum Einsatz \ref{ableitung}. Diese Funktion ist f√ºr eine geringe Datenmenge geeignet. Bei gr√∂√üeren Datenmengen entsteht ein Nachteil, welches sich auf die Wissensauspr√§gung des Netzes auswirkt. Beim R√ºckw√§rts durchlaufen entsteht ein Wissensverlust \cite{bishop.2006}. Dieser Verlust wird durch das Maxima der Ableitung der verwendeten Funktion repr√§sentiert. Dieser kann bis zu 25 \% betragen. Der entstehende Verlust w√ºrde die Klassifizierungsrate des Trainingsmodels reduzieren, welches in Abbildung \ref{fig:features11.0} dargestellt ist \cite{Kulbear.2017}.
\begin{equation}
sigm(x)'= \frac{ e^{x} }{(e^{x} +1)^2  }
\label{ableitung}
\end{equation}

\begin{figure}[h!]
	\centering
	\includegraphics[width=1.0\linewidth]{images/sigmund}
	\caption{Darstellung der Sigmoid-Funktion und dessen Ableitung \cite{Kulbear.2017}} %Generelle
	\label{fig:features11.0}
\end{figure}
Anstelle der Sigmoid-Funktion wird in den Deep-Learning-Netzen Rectified linear Units ($ReLUs$) verwendet. Diese Funktion ist dem menschlichen Neuron am √§hnlichsten und bringt zudem eine erh√∂hte Verarbeitungsgeschwindigkeit mit sich \cite{zeiler.2013}. 
\begin{equation}
y_{j} = ReLU(x_{j}) = max(0,x_{j}) 
\label{eq:ReLU}
%\caption{Rectiefied linear Units als Aktivierungsfunktion}
\end{equation}
\begin{equation}
x_{ j } = b_{ j } + \sum{ }{ }{ x_{ ij } * y_{j}}
\label{eq:Gewichte}
\end{equation}
Als N√§chstes folgt die Output-Schicht, welche die Eingangsdaten den Klassen (Vorhersagen) zuordnet. Diese Schicht ist als Softlayer konfiguriert, welche die Klassen in eine eindimensionale Matrix kategorisiert. Eine Klasse steht f√ºr eine Sprache die gelernt werden soll. Dabei ist die Matrix in dem Zahlenintervall $[0,1]$ normalisiert. Die endg√ºltige Sprachidentifikation geschieht √ºber normalisierte Werte, welche in Abbildung \ref{fig:soft} dargestellt sind. Die Werte k√∂nnen in Wahrscheinlichkeiten ausgedr√ºckt werden, in dem diese mit dem Faktor 100 multipliziert werden \cite{Kulbear.2017}.
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\linewidth]{images/softmax}
	\caption{Klassenzuordnung √ºber Wahrscheinlichkeiten in der Softmax-Konfiguration \cite{Kulbear.2017}} %Generelle
	\label{fig:soft}
\end{figure}
 Die Vorhersagen der Output-Schicht geschieht durch die Funktion $p(j)$. Dabei steht der Index l f√ºr die jeweilige Klasse, also die Sprache die gelernt werden soll.
\begin{equation}
p(j)= \frac{ exp(x_{j}) }{\sum_{l}{}{ exp(x_{l})} }
\label{eq:soft}
\end{equation}
F√ºr den vorhin erw√§hnten Gradientenabstiegsverfahren wird ebenfalls eine Kostenfunktion ben√∂tigt. Diese geschieht durch die Cross-Entropy-Loss-Funktion. 
\begin{equation}
C= \sum_{l}{}{ t_{j} * log(p_{j})} 
\label{eq:back}
\end{equation}
Diese Funktion misst die Abweichungen der Kantengewichte der Netztopologie und passt diese r√ºckwirkend an. Der Cross-Entropy-Verlust nimmt zu, wenn der vorhergesagte Wert von der tats√§chlichen Beschriftung abweicht \cite{MLCheatsheet.2017}. Bei $t_{j}$ handelt es sich um die Klasse, f√ºr die der Verlust berechnet wird \cite{GonzalezDominguez.2015}.

\subsection{Netztopologie}

\subsection{Netztopologie}
Die Netztopologie beschreibt die Infrastruktur des Netzes. Die Auswahl der Topologie bestimmt die Qualit√§t des Trainingsvorgangs. Eine zu geringe Anzahl der Neuronen f√ºhrt zu einem niedrigen Klassifizierungsrate. Eine zu hohe Anzahl w√ºrde zu einer ¸berhˆhten des Trainingsdauers f√ºhren. Aufgrund dessen fallen Topologien von Ansatz zu Ansatz unterschiedlich aus, welche unterschiedliche Spracherkennungsresultate liefern \cite{bishop.2006}. In dieser Arbeit wird der Topologienvorschlag von Gonzales et al. betrachtet. F√ºr die Eingangsdaten werden 40 Filterbanken verwendet. Diese werden ben√∂tigt, um die Daten samplen zu k√∂nnen. Als Input-Schicht werden 26 Neuronen eingesetzt. Um unerw√ºnschte Latenzzeiten zu vermeiden wird ein asymmetrischer Kontext verwendet. Die Hidden-Schicht betr√§gt vier Ebenen mit einer Gesamtzahl von 2560 Knoten. Die Output-Schicht enth√§lt wie bereits erw√§hnt eine Softmax-Konfiguration, dessen Dimension der Anzahl der Zielsprachen entspricht. Dies ist bei der Erkennung von multilingualen Sprachen eine erforderliche Konfiguration \cite{GonzalezDominguez.2015}.
 
%\begin{figure*}[h!]
%	\centering
%	\includegraphics[width=1.0\linewidth]{images/Output}
%	\caption{Netztopologie zur  \cite{GonzalezDominguez.2015}} %Generelle
%	\label{fig:topology}
%\end{figure*}
\subsection{Verbesserung des Trainingsverfahrens durch Multitasking learning (MTL)}
 Bei maschinellem Lernen wird der Fokusauf das Optimieren bestimmter Metriken, wie beispielsweise Klassifizierungsgenauigkeit und Trainingsdauer gesetzt. Daraufhin wird das Modell soweit optimiert, bis die Leistung des Modells nicht mehr gesteigert werden kann \cite{Ruder.2017} \cite{bishop.2006}. Das Lernen der einzelnen Sprachen l√§uft sequenziell ab. Hier setzt das Multitasking Learning (MTL) ein. Es werden mehrere Lernaufgaben gleichzeitig erledigt statt sequentiell, um das Trainingsvefahren effizienter zu gestalten. Das f√ºhrt zu einer verbesserten Lerneffizienz und Vorhersagegenauigkeit. Im Klassifizierungskontext zielt MTL darauf ab, die Leistung mehrerer Klassifizierungsaufgaben zu verbessern, indem sie gemeinsam erlernt werden \cite{Lu_multitasklearning}. Ein Beispiel hierf√ºr ist ein Spamfilter. Der Schl√ºssel zur erfolgreichen Anwendung von MTL besteht darin, dass die Aufgaben miteinander verkn√ºpft werden. Dies bedeutet nicht, dass die Aufgaben √§hnlich sein m√ºssen. Stattdessen bedeutet es, dass Aufgaben auf verschiedene Ebenen abstrahiert und geteilt werden. Wenn die Lernaufgaben √§hnlich sind, k√∂nnen sie gemeinsam gelernt werden. Dabei kann das Wissen zwischen Aufgaben auf andere Lernaufgaben √ºbertragen werden, welches die Trainingsdauer deutlich verk√ºrzt. MTL ist vor allem dann n√ºtzlich, wenn die Gr√∂√üe des Trainingssatzes im Vergleich zur Modellgr√∂√üe klein ist. Dabei werden grunds√§tzlich zwei Arten von MTL unterschieden: Hard parameter sharing und soft parameter sharing. \\ \\ Hard parameter sharing stellt das meist genutzte Art dar\cite{Ruder.2017}. Es wird normalerweise auf die Hidden-Schicht angewendet, indem die Aufgaben gemeinsam gelernt werden, w√§hrend die spezifischen Aufgaben separat gelernt werden. Dies wird in Abbildung \ref{fig:hard} dargestellt. Dieser Ansatz reduziert das Risiko von overfitting erheblich. Je mehr Aufgaben gleichzeitig gelernt werden, desto mehr muss das Modell eine Repr√§sentation finden, die alle Aufgaben erfassen muss. Dadurch ist die Chance auf overfitting deutlich geringer \cite{Ruder.2017} \cite{Lu_multitasklearning}.
  \begin{figure}[h!]
 	\centering
 	\includegraphics[width=0.8\linewidth]{images/hard}
 	\caption{Hard parameter sharing auf die Hidden-Schicht angewendet \cite{Kulbear.2017}.} %Generelle
 	\label{fig:hard}
 \end{figure}

